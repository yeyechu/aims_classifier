import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from torchvision import models, transforms
from PIL import Image
from config import LABELS, IMAGE_SIZE

def load_model(model_path, num_classes=6, device="cuda"):
    """
    í•™ìŠµëœ MobileNetV3-Small ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    """
    model = models.mobilenet_v3_small(weights=None)
    model.classifier[3] = nn.Linear(1024, num_classes)

    # model = models.efficientnet_b0(weights=None)
    # model.classifier[1] = nn.Linear(1280, num_classes)

    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device).eval()
    return model

def preprocess_image(image_path, device="cuda"):
    """
    ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
    """
    transform = transforms.Compose([
        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    image = Image.open(image_path).convert("RGB")
    image = transform(image).unsqueeze(0).to(device)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ í›„ ì´ë™
    return image

def infer_and_visualize(model, image, class_names, feature_map_dir):
    """
    ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ ì„ ìˆ˜í–‰í•˜ê³  Feature Mapì„ ì €ì¥ ë° ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜
    """
    activation = {}
    def get_activation(name):
        def hook(model, input, output):
            activation[name] = output.detach().cpu().numpy()
        return hook

    num = 0
    hook_layer = model.features[num]  # íŠ¹ì • ë ˆì´ì–´ ì„ íƒ
    hook_handle = hook_layer.register_forward_hook(get_activation(f"features.{num}"))
    
    # ëª¨ë¸ ì¶”ë¡  ìˆ˜í–‰
    with torch.no_grad():
        outputs = model(image)
    probabilities = F.softmax(outputs, dim=1)
    predicted_class = torch.argmax(probabilities, dim=1).cpu().item()
    confidence = probabilities.max().cpu().item()
    
    # Feature Map ì €ì¥ ë° ì‹œê°í™”
    feature_map = activation[f"features.{num}"].squeeze()
    os.makedirs(feature_map_dir, exist_ok=True)
    feature_map_path = os.path.join(feature_map_dir, "feature_map.npy")
    np.save(feature_map_path, feature_map)
    
    feature_map_image_path = os.path.join(feature_map_dir, "feature_map.png")
    fig, axes = plt.subplots(4, 4, figsize=(8, 8))
    for i, ax in enumerate(axes.flat):
        if i < feature_map.shape[0]:
            ax.imshow(feature_map[i], cmap="viridis")
            ax.axis("off")
    plt.savefig(feature_map_image_path)
    plt.close()
    
    return class_names[predicted_class], confidence

# ì‹¤í–‰ ì˜ˆì œ
if __name__ == "__main__":
    model_path = "/data/ephemeral/home/aims_image_classifier/model_pth/student_model.pth"
    #model_path = "/data/ephemeral/home/aims_image_classifier/model_pth/teacher_model.pth"

    image_path = "/data/ephemeral/home/aims_image_classifier/data/test2/image_071.png"
    feature_map_dir = "/data/ephemeral/home/aims_image_classifier/feature_maps"
    class_names = LABELS
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = load_model(model_path, num_classes=len(class_names), device=device)
    image = preprocess_image(image_path, device=device)
    predicted_label, confidence = infer_and_visualize(model, image, class_names, feature_map_dir)
    
    print(f"ğŸ” ì˜ˆì¸¡ ê²°ê³¼: {predicted_label} (Confidence: {confidence:.4f})")